		     +-------------------------+
		     |            OS           |
		     | PROJECT 4: FILE SYSTEMS |
		     |     DESIGN DOCUMENT     |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Marco Maida <mmaida@mpi-sws.org>
Marco Perronet <perronet@mpi-sws.org>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Identifies an inode. */
#define INODE_MAGIC 0x494e4f44
#define DIRECT_BLOCKS 11
#define INDIRECT_BLOCKS 65
#define D_INDIRECT_BLOCKS 3
#define METADATA_BLOCKS (1 + INDIRECT_BLOCKS + D_INDIRECT_BLOCKS * D_INDIRECT_BLOCKS)
#define INDEX_MAIN_ENTRIES (DIRECT_BLOCKS + INDIRECT_BLOCKS + D_INDIRECT_BLOCKS)
#define INDEX_BLOCK_ENTRIES 64
#define UNUSED_SIZE (123-INDEX_MAIN_ENTRIES)
#define SECTOR_ERROR (6666666)

/* When accessing a sector number relative to an inode, each of these numbers 
   represent in which part of the table that sector should be looked for.
   Another way to think of these: they are indexes that split the table. */
#define INODE_ACCESS_DIRECT (DIRECT_BLOCKS - 1)
#define INODE_ACCESS_INDIRECT \
(INODE_ACCESS_DIRECT + (INDIRECT_BLOCKS * INDEX_BLOCK_ENTRIES)) // 4170
#define INODE_ACCESS_MAX \
(INODE_ACCESS_INDIRECT + \
(D_INDIRECT_BLOCKS * INDEX_BLOCK_ENTRIES * INDEX_BLOCK_ENTRIES) \
- METADATA_BLOCKS) // 16383

union index_table
  {
    block_sector_t main_index[INDEX_MAIN_ENTRIES];		/* Main index of next blocks */
    block_sector_t block_index[INDEX_BLOCK_ENTRIES];	/* Supplementary index if it is an index block */
  };

/* On-disk inode.
   Must be exactly BLOCK_SECTOR_SIZE bytes long. */
struct inode_disk
  {
    block_sector_t start;               	/* First data sector. */
    block_sector_t parent;								/* The directory containing the inode */
    off_t length;                       	/* File size in bytes. */
  	union index_table index;							/* Main index or supplementary index */
    uint32_t is_index_block;							/* Is it a normal data block or an index block? */
    unsigned magic;                     	/* Magic number. */
    uint32_t unused[UNUSED_SIZE];    			/* Not used. */
  };

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

We implemented a multilevel index. By choosing the appropriate values for the
following variables, a file can be exactly at most 8MB in size. The variables 
are parametrized in the actual implementation through #define, it's then possible
to tweak them to change the maximum file size.

x = 11. Number of direct blocks in the main table of an inode (DIRECT_BLOCKS)
y = 65. Number of indirect blocks in the main table of an inode (INDIRECT_BLOCKS)
z = 3. Number of doubly indirect blocks in the main table of an inode (D_INDIRECT_BLOCKS)
e = 64. Number of entries in an index inode, which is an inode that has a table
of other inodes, used for indirection (INDEX_BLOCK_ENTRIES)

total_blocks = x + y*e + z*e^2
metadata_blocks = 1 + y + z^2
memory_blocks = total_blocks - metadata_blocks = 16384 (8MB)

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

Each inode uses a lock to synchronize the loading from disk of the disk_inode,
and another to handle file growth, that can be consequently done by only one thread 
at time.
A process only acquires the growth lock if it wants to extend the file; any read or 
write that does not exceed the file length can therefore happen in parallel. 

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

To handle this, we introduced a new field in the inode structure called
logical length. When a file is extended, its physical length will grow, but
the logical length will stay the same until the file is written for the first
time by the process. Any read call will use the logical length as length of the
file, so it will not be aware of the extended part. This part requires synchronization
on one hand, and careful updates of the two length variables. The former challenge is 
solved with a lock used to synchronize the growth action (lock is per-inode). 
The logical length system is delicate, because it intertwines with the inode load and
flush mechanism. The logical length is initialized when the inode is loaded, is always 
stored in memory, and is guaranteed to be unified with the physical one before the inode 
is closed.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

Readers can work in parallel, and also the writers
can. During races between writers and readers, accesses to the same block are 
handled by the buffer cache: all processes wait on the same queue, and then 
decide whether they are currently allowed to perform the operation they want 
(R/W). Starvation in theory is still possible, but limited to a low probability.
If two processes try to extend the same file, then one of them will win, and 
the other will have to wait until the winner finishes one block. After this, the
second process will be able to overwrite the newly created block, and at the same
time the first could be extending the file even more. When the number of processes
that are trying to extend grows, there will still be one winner, and the problem for the
others will be reduced to the case of the many-writers race (as long as the extension
of one block finishes).

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

The distribution of the blocks is based under the assumption that most 
files will have a medium size, and that there will be very few large
files. For this reason, the divison of blocks is the following:

11 DIRECT_BLOCKS
65 INDIRECT_BLOCKS
3 D_INDIRECT_BLOCKS

Indirect blocks point to index inode blocks, rather than normal inodes.
These blocks contain a table of addresses of inodes or other index inodes.
The two types of inodes can be distinguished with the flag is_index_block:
depending on its value, "index" can be either a "main_index" (normal inodes)
or a "block_index" (index inodes).
The number of entries in the main index depend on the indirect block distribution,
while the entries in index inodes are set to 64 (parameter INDEX_BLOCK_ENTRIES).
Files that are 11 or less blocks in size can be accessed directly 
without any level of indirection, it is assumed that small files are
fairly common among files.

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
  {
	...
    struct dir *curr_dir;               /* Current working directory */
    ...
  }

/* A single directory entry. */
struct dir_entry 
  {
    block_sector_t inode_sector;        /* Sector number of header. */
    char name[NAME_MAX + 1];            /* Null terminated file or directory name. */
    bool in_use;                        /* In use or free? */
    bool is_dir;                        /* Is a directory or a file? */
  };

union index_table
  {
    block_sector_t main_index[INDEX_MAIN_ENTRIES];		/* Main index of next blocks */
    block_sector_t block_index[INDEX_BLOCK_ENTRIES];	/* Supplementary index if it is an index block */
  };

/* On-disk inode.
   Must be exactly BLOCK_SECTOR_SIZE bytes long. */
struct inode_disk
  {
    block_sector_t start;               	/* First data sector. */
    block_sector_t parent;								/* The directory containing the inode */
    off_t length;                       	/* File size in bytes. */
  	union index_table index;							/* Main index or supplementary index */
    uint32_t is_index_block;							/* Is it a normal data block or an index block? */
    unsigned magic;                     	/* Magic number. */
    uint32_t unused[UNUSED_SIZE];    			/* Not used. */
  };

/* In-memory inode. */
struct inode 
  {
    struct list_elem elem;              /* Element in inode list. */
    block_sector_t sector;              /* Sector number of disk location. */
    int open_cnt;                       /* Number of openers. */
    int open_fd_cnt;                    /* Number of open fds on this dir. */
    int cwd_cnt;                        /* Number of processes that have this dir as cwd. */
    bool removed;                       /* True if deleted, false otherwise. */
    int deny_write_cnt;                 /* 0: writes ok, >0: deny writes. */
    struct inode_disk* data;            /* Inode content. */
    struct lock inode_lock;             /* Used to synchronize file loading */
    struct lock inode_growth;           /* Used to synchronize file growth */
    int access_count;                   /* Number of threads currently using this inode */
    off_t logical_length;               /* Physical size minus what still needs to be initialized */
  };

struct dir 
  {
    struct inode *inode;                /* Backing store. */
    struct lock dir_lock;               /* Used to synch dir modifications */
    off_t pos;                          /* Current position. */
  };

/* Represents an open file. */
struct file_descriptor 
  {
    int fd_num;
    struct file *open_file;
    struct dir *open_dir;
    tid_t owner;
    bool is_dir;

    struct list_elem elem; 
  };

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

The only difference is the starting directory. For absolute paths the initial
directory is root, and for relative paths it is the current working 
directory of the process. From here, at every iteration the working directory
is changed, based on the current entry in the string, until the target directory 
is reached. Special names in the string ("." "..") are treated as special 
cases during the directory lookup: they are not actual entries in directories.
Their only effect is to change the working directory during the lookup.
For any other normal entry, a simple linear seach in the parent directory
is performed.

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

Operations on the same directory are guarded by a (per-directory) lock.
Hence, one operation will go first, and the other will not succeed.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

No, it is not possible to remove a directory in this situation.
struct inode keeps two counters: open_fd_cnt and cwd_cnt. They will keep count
of file descriptors that refer to the open directory, and the number of 
processes that have the directory as current working directory. If any of 
the counters is greater than zero, then the directory can't be removed.

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

Because the current working directory is process-specific, it is 
represented with a field in struct thread. 
It is assumed that a directory must be open in order to be a
current working directory. Because of this, the field is of type 
struct dir*, which is used to represent open directories.

			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

#define MAX_CACHE_SECTORS 64 //dimension of the cache
#define BC_DAEMON_FLUSH_SLEEP_MS 1000 //Interval between activations of the automatic flush
#define MAX_READ_AHEAD 10 //maximum number of entries that can request a read-ahead at the same time.

struct buffer_cache_entry
{
	block_sector_t sector;              /* Sector number of disk location. */
	char data [BLOCK_SECTOR_SIZE];		  /* Data contained in the cache */
	bool is_in_second_chance;			      /* Whether the entry is in second chance */			
	bool is_dirty;						          /* Whether the entry is in second dirty */			

	struct list_elem elem;              /* List element. */
};

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

To evict a block, we use a slightly modified version of the clock algorithm,
in which we always start from the top of the list, and we cycle looking 
for an entry in a second chance fashion. To reduce cache misses, we organize
the eviction in rounds and gradually consider a larger classes of candidates.
Each cache entry can have three properties:
- Is currently dirty
- Is currently locked
- Is currently being read (readers count > 0)
During the first iteration, we look for a free entry (may be skipped if free count == 0). 
In the second, we put in second chance every non-dirty entry. If we find an entry in 
second-chance, we try to acquire it. From the third iteration onwards, we put anything 
in second change. Entries that are currently locked or have readers are simply ignored.
Intuitively, this makes sense, because it suggests that these entries are popular and 
should not be evicted. On the other hand, this may cause starvation (although it is 
very unlikely). As a safety measure, we allow the algorithm to actually wait on the lock 
of a cell after a certain number of failed iterations. In practice, this limit was never met.

>> C3: Describe your implementation of write-behind.

Entries are not flushed upon write, but rather upon eviction, or periodically 
by the flush daemon. We use a dirty bit in order to decide whether an entry 
should be flushed or not. We implemented a daemon (running on another thread) that sleeps
for a fixed amount of time, then wakes up and looks for entries to flush.

>> C4: Describe your implementation of read-ahead.

We use an array of read-ahead requests, bounded with fixed number of maximum requests.
Unlike the write-behind daemon, the read ahead thread will check for requests only when
asked to. After a block is read, the daemon is triggered by signaling on a specific semaphore.
We used a semaphore and not a condition because, since the daemon is asynchronous, we could 
have another request while it is running. We therefore want the daemon to check again after one
loop is completed. In the worst case, this leads to some lost computation power, but considered
the length of the maximum requests (currently ten), this is negligible. On the other hand, this
mechanism allows the read-ahead mechanism to be completely independent, and act (from the point
of view of the buffer cache) like a normal process. 

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

Each entry in the cache has its own lock. Readers only get the lock 
to signal their presence (they increase a counter) and to signal
their leave (decrease the counter). Writers hold the lock for the
entire operation. In order to evict a frame, a process must be able
to:
1 - get the lock of the entry
2 - make sure that there are no active readers (using the counter)
It is therefore impossible that an entry is evicted while being used.
This causes some problems on the eviction side, addressed in [C2]

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

As explained in [C5], both readers and writers acquire the entry lock
before proceeding. Since the eviction takes place with lock acquired,
readers and writers will halt.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

Buffer caching is useful when few blocks are read and written over and
over, like in case of a very small resource with extreme contention.

Read-ahead can be very useful when copying large files 
because every read, except the first and last one, will be anticipated.

Write-behind benefits programs that write to the same blocks many times
in a short timespan. The periodic automatic flush of the entries 
is actually a safety/consistency feature, because we could just leave the
eviction system do the job (or flush everything at shutdown).

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
 
